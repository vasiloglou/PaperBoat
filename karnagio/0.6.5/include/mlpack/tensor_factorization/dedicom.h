/*
Copyright Â© 2010, Ismion Inc
All rights reserved.
http://www.ismion.com/

Redistribution and use in source and binary forms, with or without
modification IS NOT permitted without specific prior written
permission. Further, neither the name of the company, Ismion
LLC, nor the names of its employees may be used to endorse or promote
products derived from this software without specific prior written
permission.

THIS SOFTWARE IS PROVIDED BY THE ISMION INC "AS IS" AND ANY
EXPRESSED OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COMPANY BE LIABLE FOR
ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT,
STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING
IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
POSSIBILITY OF SUCH DAMAGE.
*/

#ifndef PAPERBOAT_INCLUDE_MLPACK_TENSOR_FACTORIZATION_DEDICOM_
#define PAPERBOAT_INCLUDE_MLPACK_TENSOR_FACTORIZATION_DEDICOM_
#include "tensor_factoriazation.h"

namespace fl { namespace ml {
  
  /**
   *  @brief Dedicom tensor factorization
   *     X_t = A B_t C B_t A'
   *     B is a diagonal tensor B_t is a diagonal matrix
   *     X is N x N x t
   *     A is N x k
   *     B is t x k 
   *     C is k x k
   */
  template<typename WorkSpaceType>
  template<typename TableType,
               bool A_REGULARIZATION,
               bool B_REGULARIZATION,
               bool C_REGULARIZATION,
               bool L2_REGULARIZATION
               > 
  void TensorFactorization<WorkSpaceType>::Dedicom::LbfgsFun<
      TableType,
      A_REGULARIZATION,
      B_REGULARIZATION,
      C_REGULARIZATION,
      L2_REGULARIZATION
  >::AssignMats(
      fl::data::MonolithicPoint<double> &variable,
      fl::dense::Matrix<double> *a_mat,
      fl::dense::Matrix<double> *b_mat,
      fl::dense::Matrix<double> *c_mat) {
    a_mat->Alias(variable.ptr(),
        rank_,
        (*tensor_)[0]->n_entries());
    b_mat->Alias(variable.ptr()+a_mat->n_elements(),
        rank_,
        tensor_->size());
    c_mat->Alias(variable.ptr()+a_mat->n_elements()
                 +b_mat->n_elements(),
                 rank_,
                 (*tensor_)[0]->n_attributes());

  }

  template<typename WorkSpaceType>
  template<typename TableType>
  void TensorFactorization<WorkSpaceType>::Dedicom::AssignMats(fl::data::MonolithicPoint<double> &variable,
              std::vector<boost::shared_ptr<TableType> > &tensor,
              int32 rank,
              fl::dense::Matrix<double> *a_mat,
              fl::dense::Matrix<double> *b_mat,
              fl::dense::Matrix<double> *c_mat) {
    a_mat->Alias(variable.ptr(),
        rank,
        tensor[0]->n_entries());
    b_mat->Alias(variable.ptr()+a_mat->n_elements(),
        rank,
        tensor.size());
    c_mat->Alias(variable.ptr()+a_mat->n_elements()
                 +b_mat->n_elements(),
                 rank,
                 tensor[0]->n_attributes());
 
  }

  template<typename WorkSpaceType>
  template<typename TableType,
           bool A_REGULARIZATION,
           bool B_REGULARIZATION,
           bool C_REGULARIZATION,
           bool L2_REGULARIZATION
          >
  double TensorFactorization<WorkSpaceType>::Dedicom::LbfgsFun<
      TableType,
      A_REGULARIZATION,
      B_REGULARIZATION,
      C_REGULARIZATION,
      L2_REGULARIZATION
  >::tensor_sq_norm() const {
    return tensor_sq_norm_;
  }

  template<typename WorkSpaceType>
  template<typename TableType,
           bool A_REGULARIZATION,
           bool B_REGULARIZATION,
           bool C_REGULARIZATION,
           bool L2_REGULARIZATION
          >
  double TensorFactorization<WorkSpaceType>::Dedicom::LbfgsFun<
      TableType,
      A_REGULARIZATION,
      B_REGULARIZATION,
      C_REGULARIZATION,
      L2_REGULARIZATION
  >::eval_result() const {
    return eval_result_;
  }

  template<typename WorkSpaceType>
  template<typename TableType,
           bool A_REGULARIZATION,
           bool B_REGULARIZATION,
           bool C_REGULARIZATION,
           bool L2_REGULARIZATION
          >
  double TensorFactorization<WorkSpaceType>::Dedicom::LbfgsFun<
      TableType,
      A_REGULARIZATION,
      B_REGULARIZATION,
      C_REGULARIZATION,
      L2_REGULARIZATION
  >::factorization_error() const {
    return factorization_error_;
  }

  template<typename WorkSpaceType>
  template<typename TableType,
           bool A_REGULARIZATION,
           bool B_REGULARIZATION,
           bool C_REGULARIZATION,
           bool L2_REGULARIZATION
          >
  void TensorFactorization<WorkSpaceType>::Dedicom::LbfgsFun<
      TableType,
      A_REGULARIZATION,
      B_REGULARIZATION,
      C_REGULARIZATION,
      L2_REGULARIZATION
  >::Init(
      std::vector<boost::shared_ptr<TableType> > *tensor,
      int32 factorization_rank,
      double a_regularization,
      double b_regularization, 
      double c_regularization) {
    tensor_=tensor;
    rank_=factorization_rank;
    a_regularization_=a_regularization;
    b_regularization_=b_regularization;
    c_regularization_=c_regularization;
    num_dimensions_=(tensor_->size()
      +(*tensor_)[0]->n_entries()
      +(*tensor_)[0]->n_attributes())*rank_;
     tensor_sq_norm_=0;
    typename TableType::Point_t point;
    for(size_t i=0; i<tensor->size(); ++i) {  
      for(index_t j=0; j<(*tensor)[i]->n_entries(); ++j) {
        (*tensor)[i]->get(j, &point);
        tensor_sq_norm_+=fl::la::Dot(point, point);
      }
    }
  }

  template<typename WorkSpaceType>
  template<typename TableType,
           bool A_REGULARIZATION,
           bool B_REGULARIZATION,
           bool C_REGULARIZATION,
           bool L2_REGULARIZATION
          >
  void TensorFactorization<WorkSpaceType>::Dedicom::LbfgsFun<
      TableType,
      A_REGULARIZATION,
      B_REGULARIZATION,
      C_REGULARIZATION,
      L2_REGULARIZATION
  >::Gradient(
      const fl::data::MonolithicPoint<double> &variable,
      fl::data::MonolithicPoint<double> *gradient) {
    fl::dense::Matrix<double> a_mat;
    fl::dense::Matrix<double> b_mat;
    fl::dense::Matrix<double> c_mat;
    fl::dense::Matrix<double> grad_a_mat;
    fl::dense::Matrix<double> grad_b_mat;
    fl::dense::Matrix<double> grad_c_mat;

    AssignMats(const_cast<fl::data::MonolithicPoint<double> &>(variable), &a_mat, 
        &b_mat, &c_mat);
    gradient->SetZero();
    AssignMats(*gradient, &grad_a_mat, &grad_b_mat, &grad_c_mat);
    typedef typename TableType::Point_t Point_t;
    Point_t point;
    for(size_t i=0; i<tensor_->size(); ++i) {
      fl::dense::Matrix<double> scaled_a;
      scaled_a.Init(a_mat.n_rows(), a_mat.n_cols());
      scaled_a_transp.Init(a_mat.n_rows(), a_mat.n_cols());
      scaled_a.SetAll(0.0);
      scaled_a_transp.SetAll(0,0);
      for(index_t l=0; l<a_mat.n_cols(); ++l) {
        for(index_t k1=0; k1<a_mat.n_rows(); ++k1) {
          double v1=0;
          for(index_t k2=0; k2<a_mat.n_rows(); ++k2) {
            v1+=c_mat.get(k1, k2)*b_mat.get(k2, i)*a_mat.get(k2, l);    
            v2+=c_mat.get(k2, k1)*b_mat.get(k2, i)*a_mat.get(k2, l);    
          }
          scaled_a.set(k1, l, v1);
          scaled_a_transp.set(k1, l, v2);
        }
      }
      for(index_t j=0; j<(*tensor_)[i]->n_entries(); ++j) {
        (*tensor_)[i]->get(j, &point);
        for(typename Point_t::iterator it=point.begin(); 
            it!=point.end(); ++it) {
          double predicted_value=0;        
          for(size_t k1=0; k1<rank_; ++k1) {
            predicted_value+=a_mat.get(k1, j)
                *scaled_a.get(k1, it.attribute())*b_mat.get(k1, i);
            
          }
          double error=-2*(it.value()-predicted_value);
          for(size_t k1=0; k1<rank_; ++k1) {
            grad_a_mat.set(k1, j, 
                grad_a_mat.get(k1, j)
                -error* scaled_a.get(k1, it.attribute()))*b_mat.get(k1, i);
             
            grad_a_mat.set(k1, it.attribute(),
                grad_a_mat.get(k1, it.attribute())
                -error *scaled_a_transp.get(k1, j)*b_mat.get(k1, i)) ;
          
            double value=0;
            for(size_t k2=0; k2<k_rank_; ++k2) {
              if (k1==k2) {
                value+=a_mat.get(k2, j) * scaled_a.get(k2, it.attribute())    
                +a_mat.get(k2, j)*b_mat.get(k1, i) * 
                c_mat.get(k1, k2)*a_mat.get(k2, it.attribute()); 
              } else {
                value+=a_mat.get(k2, j)*b_mat.get(k1, i) 
                  * c_mat.get(k2, k1)*a_mat.get(k2, it.attribute()); 
              }
            }
            grad_b_mat.set(k1, i, 
                grad_b_mat.get(k1, i)
                -error*value);
            for(size_t k2=0; k2<k_rank_; ++k2)
              grad_c_mat.set(k1, k2,
                  grad_c_mat.get(k1, k2)
                  -a_mat.get(k1 ,j) * b_mat.get(k1, i) 
                  * b_mat.get(k2 ,i) * a_mat.get(k2, it.attribute()));
          }
        }     
      }
    }
    if (A_REGULARIZATION) {
      fl::la::AddExpert(2*a_regularization_, a_mat, &grad_a_mat);
    }
    if (B_REGULARIZATION) {
      fl::la::AddExpert(2*b_regularization_, b_mat, &grad_b_mat);
    }
    if (C_REGULARIZATION) {
      fl::la::AddExpert(2*c_regularization_, c_mat, &grad_c_mat);
    }


  }

  template<typename WorkSpaceType>
  template<typename TableType,
           bool A_REGULARIZATION,
           bool B_REGULARIZATION,
           bool C_REGULARIZATION,
           bool L2_REGULARIZATION
          >
  double TensorFactorization<WorkSpaceType>::Dedicom::LbfgsFun<
      TableType,
      A_REGULARIZATION,
      B_REGULARIZATION,
      C_REGULARIZATION,
      L2_REGULARIZATION
  >::Evaluate(
      const fl::data::MonolithicPoint<double> &variable) {
    typedef typename TableType::Point_t TPoint_t;
    TPoint_t point;
    typedef typename WorkSpaceType::DefaultTable_t::Point_t FPoint_t;
    double error=0;
    fl::dense::Matrix<double> a_mat;
    fl::dense::Matrix<double> b_mat;
    fl::dense::Matrix<double> c_mat;
    AssignMats(const_cast<fl::data::MonolithicPoint<double>&>(variable), 
        &a_mat, &b_mat, &c_mat);
    for(size_t i=0; i<tensor_->size(); ++i) {
      fl::dense::Matrix<double> scaled_a;
      scaled_a.Init(a_mat.n_rows(), a_mat.n_cols());
      scaled_a_transp.Init(a_mat.n_rows(), a_mat.n_cols());
      scaled_a.SetAll(0.0);
      scaled_a_transp.SetAll(0,0);
      for(index_t l=0; l<a_mat.n_cols(); ++l) {
        for(index_t k1=0; k1<a_mat.n_rows(); ++k1) {
          double v1=0;
          for(index_t k2=0; k2<a_mat.n_rows(); ++k2) {
            v1+=c_mat.get(k1, k2)*b_mat.get(k2, i)*a_mat.get(k2, l);    
            v2+=c_mat.get(k2, k1)*b_mat.get(k2, i)*a_mat.get(k2, l);    
          }
          scaled_a.set(k1, l, v1);
          scaled_a_transp.set(k1, l, v2);
        }
      }
      for(index_t j=0; j<(*tensor_)[i]->n_entries(); ++j) {
        (*tensor_)[i]->get(j, &point);
        for(typename Point_t::iterator it=point.begin(); 
            it!=point.end(); ++it) {
          double predicted_value=0;        
          for(size_t k1=0; k1<rank_; ++k1) {
            predicted_value+=a_mat.get(k1, j)
                *scaled_a.get(k1, it.attribute())*b_mat.get(k1, i);
            
          }
          double error=-2*(it.value()-predicted_value);
          error+=fl::math::Pow<double,2,1>(it.value()-predicted_value);
        }     
      }
    }
    factorization_error_=error;
    if (A_REGULARIZATION) {
      error+=a_regularization_*fl::math::Pow<double, 2, 1>(fl::la::LengthEuclidean(a_mat));          
    }
    if (B_REGULARIZATION) {
      error+=b_regularization_*fl::math::Pow<double, 2, 1>(fl::la::LengthEuclidean(b_mat));          
    }
    if (C_REGULARIZATION) {
      error+=c_regularization_*fl::math::Pow<double, 2, 1>(fl::la::LengthEuclidean(c_mat));            
    }
    eval_result_=error;  
    return error; 
  }

  template<typename WorkSpaceType>
  template<typename TableType,
           bool A_REGULARIZATION,
           bool B_REGULARIZATION,
           bool C_REGULARIZATION,
           bool L2_REGULARIZATION
          >
  const index_t TensorFactorization<WorkSpaceType>::Dedicom::LbfgsFun<
      TableType,
      A_REGULARIZATION,
      B_REGULARIZATION,
      C_REGULARIZATION,
      L2_REGULARIZATION
  >::num_dimensions() const {
    return num_dimensions_;
  }

  template<typename WorkSpaceType>
  template<typename TableType, typename FunType, typename EngineType>
  bool TensorFactorization<WorkSpaceType>::Optimizer(
      std::vector<boost::shared_ptr<TableType> > &tensor, 
      FunType &fun,
      EngineType &engine,
      int32 parafac_rank,
      double a_regularization,
      double b_regularization,
      double c_regularization,
      int32 num_iterations,
      int32 max_num_line_searches_in,
      int32 num_basis,
      fl::data::MonolithicPoint<double> *iterate) {
    fun.Init(&tensor,
              parafac_rank,
              a_regularization,
              b_regularization,
              c_regularization);
    bool optimized;
    
    engine.Init(fun, num_basis);
    engine.set_max_num_line_searches(max_num_line_searches_in);
    fun.Evaluate(*iterate);
    double error=
        double(int32(fl::math::Pow<double, 1, 2>(
                fun.factorization_error()/fun.tensor_sq_norm())
                *10000))/100;
    fl::logger->Message()<<"iteration="<<0
        <<", error="<<error<<"%"<<std::endl;
    if (num_iterations>0) {
      for(int32 i=0; i<num_iterations/5; ++i) {
        optimized=engine.Optimize(5,
                                  iterate);
        double error=
            double(int32(fl::math::Pow<double, 1, 2>(
                    fun.factorization_error()/fun.tensor_sq_norm())
                *10000))/100;
        fl::logger->Message()<<"iteration="<<(i+1)*5
                <<", error="<<error<<"%"<<std::endl;
        if (optimized==false) {
          return optimized;
        }
      }
      if (num_iterations % 5>0) {      
        optimized=engine.Optimize(num_iterations % 5, iterate);
        double error=
            double(int32(fl::math::Pow<double, 1, 2>(
                    fun.factorization_error()/fun.tensor_sq_norm())
                *10000))/100;
        fl::logger->Message()<<"iteration="<<num_iterations
                <<", error="<<error<<"%"<<std::endl;
      }
    } else {
      optimized=engine.Optimize(num_iterations % 5, iterate);
      double error=
            double(int32(fl::math::Pow<double, 1, 2>(
                    fun.factorization_error()/fun.tensor_sq_norm())
                *10000))/100;
      fl::logger->Message()<<"iteration="<<num_iterations
                <<", error="<<error<<"%"<<std::endl;

    }
    return optimized;
  }

  template<typename WorkSpaceType>
  template<typename TableType>
  void TensorFactorization<WorkSpaceType>::Dedicom::ComputeSGD(
      std::vector<boost::shared_ptr<TableType> > &tensor, 
      int32 rank,
      const double a_regularization,
      const double b_regularization,
      const double c_regularization,
      double step0,
      int32 epochs,
      int32 num_iterations,
      boost::shared_ptr<typename WorkSpaceType::DefaultTable_t> *a_table,
      boost::shared_ptr<typename WorkSpaceType::DefaultTable_t> *b_table,
      boost::shared_ptr<typename WorkSpaceType::DefaultTable_t> *c_table) {
 
    FL_SCOPED_LOG(Sgd);
    fl::logger->Message()<<"SGD is not implemented yet"<<std::endl;
  }

  template<typename WorkSpaceType>
  template<typename TableType>
  void TensorFactorization<WorkSpaceType>::Dedicom::ComputeDedicom(
        std::vector<boost::shared_ptr<TableType> > &tensor,
        int32 parafac_rank,
        double a_regularization,
        double b_regularization,
        double c_regularization,
        int32 num_basis,
        int32 max_num_line_searches_in,
        int32 num_iterations,
        boost::shared_ptr<typename WorkSpaceType::DefaultTable_t> *a_table,
        boost::shared_ptr<typename WorkSpaceType::DefaultTable_t> *b_table,
        boost::shared_ptr<typename WorkSpaceType::DefaultTable_t> *c_table) {
   
    FL_SCOPED_LOG(Lbfgs);
    bool optimized=false;
    fl::data::MonolithicPoint<double> iterate;
    iterate.Init(
        (tensor.size()
         +tensor[0]->n_entries()
         +tensor[0]->n_attributes())*parafac_rank);
    {
      fl::dense::Matrix<double> a_mat;
      fl::dense::Matrix<double> b_mat;
      fl::dense::Matrix<double> c_mat;
      AssignMats(
        iterate,
        tensor,
        parafac_rank,
        &a_mat,
        &b_mat,
        &c_mat);
      
      typename WorkSpaceType::DefaultTable_t::Point_t point;
      for(index_t i=0; i<(*a_table)->n_entries(); ++i) {
        (*a_table)->get(i, &point);
        memcpy(a_mat.ptr()+i*parafac_rank, point.template dense_point<double>().ptr(), 
            parafac_rank*sizeof(double));      
      }

      for(index_t i=0; i<(*b_table)->n_entries(); ++i) {
        (*b_table)->get(i, &point);
        memcpy(b_mat.ptr()+i*parafac_rank, point.template dense_point<double>().ptr(), 
            parafac_rank*sizeof(double));      
      }

      for(index_t i=0; i<(*c_table)->n_entries(); ++i) {
        (*c_table)->get(i, &point);
        memcpy(c_mat.ptr()+i*parafac_rank, point.template dense_point<double>().ptr(), 
            parafac_rank*sizeof(double));      
      }
    }

    int choice=(a_regularization>0)*4
      +(b_regularization>0)*2
      +(c_regularization>0);
    switch (choice) {
      case 0: 
        {
          Lbfgs<LbfgsFun<TableType, false, false, false, true> > engine;
          LbfgsFun<TableType, false, false, false, true> fun;
          optimized=Optimizer(
            tensor, 
            fun,
            engine,
            parafac_rank,
            a_regularization,
            b_regularization,
            c_regularization,
            num_iterations,
            max_num_line_searches_in,
            num_basis,
            &iterate);

        }
        break;
      case 1:
        {
          Lbfgs<LbfgsFun<TableType, false, false, true, true> > engine;
          LbfgsFun<TableType, false, false, true, true> fun;
          optimized=Optimizer(
            tensor, 
            fun,
            engine,
            parafac_rank,
            a_regularization,
            b_regularization,
            c_regularization,
            num_iterations,
            max_num_line_searches_in,
            num_basis,
            &iterate);
        }
        break;
      case 2:
        {
          Lbfgs<LbfgsFun<TableType, false, true, false, true> > engine;
          LbfgsFun<TableType, false, true, false, true> fun;
          optimized=Optimizer(
            tensor, 
            fun,
            engine,
            parafac_rank,
            a_regularization,
            b_regularization,
            c_regularization,
            num_iterations,
            max_num_line_searches_in,
            num_basis,
            &iterate);
        }
        break;
      case 3:
        {
          Lbfgs<LbfgsFun<TableType, false, true, true, true> > engine;
          LbfgsFun<TableType, false, true, true, true> fun;
          optimized=Optimizer(
            tensor, 
            fun,
            engine,
            parafac_rank,
            a_regularization,
            b_regularization,
            c_regularization,
            num_iterations,
            max_num_line_searches_in,
            num_basis,
            &iterate);
        }
        break;
      case 4:
        {
          Lbfgs<LbfgsFun<TableType, true, false, false, true> > engine;
          LbfgsFun<TableType, true, false, false, true> fun;
          optimized=Optimizer(
            tensor, 
            fun,
            engine,
            parafac_rank,
            a_regularization,
            b_regularization,
            c_regularization,
            num_iterations,
            max_num_line_searches_in,
            num_basis,
            &iterate);
        }
        break;
      case 5:
        {
          Lbfgs<LbfgsFun<TableType, true, false, true, true> > engine;
          LbfgsFun<TableType, true, false, true, true> fun;
          optimized=Optimizer(
            tensor, 
            fun,
            engine,
            parafac_rank,
            a_regularization,
            b_regularization,
            c_regularization,
            num_iterations,
            max_num_line_searches_in,
            num_basis,
            &iterate);
        }
        break;
      case 6:
        {
          Lbfgs<LbfgsFun<TableType, true, true, false, true> > engine;
          LbfgsFun<TableType, true, true, false, true> fun;
          optimized=Optimizer(
            tensor, 
            fun,
            engine,
            parafac_rank,
            a_regularization,
            b_regularization,
            c_regularization,
            num_iterations,
            max_num_line_searches_in,
            num_basis,
            &iterate);
        }
        break;
      case 7:
        {
          Lbfgs<LbfgsFun<TableType, true, true, true, true> > engine;
          LbfgsFun<TableType, true, true, true, true> fun;
          optimized=Optimizer(
            tensor, 
            fun,
            engine,
            parafac_rank,
            a_regularization,
            b_regularization,
            c_regularization,
            num_iterations,
            max_num_line_searches_in,
            num_basis,
            &iterate);
        }
        break;
    }
    if (optimized==false) {
      fl::logger->Warning()<<"Optimization with LBFGS failed"<<std::endl;
    }
    {
      fl::dense::Matrix<double> a_mat;
      fl::dense::Matrix<double> b_mat;
      fl::dense::Matrix<double> c_mat;
      AssignMats(
        iterate,
        tensor,
        parafac_rank,
        &a_mat,
        &b_mat,
        &c_mat);
      
      typename WorkSpaceType::DefaultTable_t::Point_t point;
      for(index_t i=0; i<(*a_table)->n_entries(); ++i) {
        (*a_table)->get(i, &point);
        memcpy(point.template dense_point<double>().ptr(), a_mat.ptr()+i*parafac_rank, parafac_rank*sizeof(double));      
      }
      for(index_t i=0; i<(*b_table)->n_entries(); ++i) {
        (*b_table)->get(i, &point);
        memcpy(point.template dense_point<double>().ptr(), b_mat.ptr()+i*parafac_rank, parafac_rank*sizeof(double));      
      }
      for(index_t i=0; i<(*c_table)->n_entries(); ++i) {
        (*c_table)->get(i, &point);
        memcpy(point.template dense_point<double>().ptr(), c_mat.ptr()+i*parafac_rank, parafac_rank*sizeof(double));      
      }
    }
  }

}}
#endif
